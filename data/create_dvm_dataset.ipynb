{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stympopper/.conda/envs/selfsuper/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_columns = 700\n",
    "\n",
    "BASE = '/home/stympopper/data/DVMdata'\n",
    "TABLES = join(BASE, 'tables_V2.0')\n",
    "FEATURES = join(BASE, 'features')\n",
    "\n",
    "front_view_only = False\n",
    "\n",
    "from typing import List\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import k_means, SpectralClustering\n",
    "import multiprocessing as mp\n",
    "\n",
    "ANALYSIS = join(BASE, 'analysis')\n",
    "\n",
    "def conf_matrix_from_matrices(mat_gt, mat_pred):\n",
    "  overlap_and = (mat_pred & mat_gt)\n",
    "  tp = overlap_and.sum()\n",
    "  fp = mat_pred.sum()-overlap_and.sum()\n",
    "  fn = mat_gt.sum()-overlap_and.sum()\n",
    "  tn = mat_gt.shape[0]**2-(tp+fp+fn)\n",
    "  return tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_or_save(obj, path, index=None, header=None):\n",
    "  if isinstance(obj, pd.DataFrame):\n",
    "    if index is None or header is None:\n",
    "      raise ValueError('Index and header must be specified for saving a dataframe')\n",
    "    if os.path.exists(path):\n",
    "      if not header:\n",
    "        saved_df = pd.read_csv(path,header=None)\n",
    "      else:\n",
    "        saved_df = pd.read_csv(path)\n",
    "      naked_df = saved_df.reset_index(drop=True)\n",
    "      naked_df.columns = range(naked_df.shape[1])\n",
    "      naked_obj = obj.reset_index(drop=not index)\n",
    "      naked_obj.columns = range(naked_obj.shape[1])\n",
    "      if naked_df.round(6).equals(naked_obj.round(6)):\n",
    "        return\n",
    "      else:\n",
    "        diff = (naked_df.round(6) == naked_obj.round(6))\n",
    "        diff[naked_df.isnull()] = naked_df.isnull() & naked_obj.isnull()\n",
    "        assert diff.all().all(), \"Dataframe is not the same as saved dataframe\"\n",
    "    else:\n",
    "      obj.to_csv(path, index=index, header=header)\n",
    "  else:\n",
    "    if os.path.exists(path):\n",
    "      saved_obj = torch.load(path)\n",
    "      if isinstance(obj, list):\n",
    "        for i in range(len(obj)):\n",
    "          check_array_equality(obj[i], saved_obj[i])\n",
    "      else:\n",
    "        check_array_equality(obj, saved_obj)\n",
    "    else:\n",
    "      print(f'Saving to {path}')\n",
    "      torch.save(obj, path)\n",
    "\n",
    "\n",
    "def check_array_equality(ob1, ob2):\n",
    "  if torch.is_tensor(ob1) or isinstance(ob1, np.ndarray):\n",
    "    assert (ob2 == ob1).all()\n",
    "  else:\n",
    "    assert ob2 == ob1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tabular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2968873/622457649.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ad_data = pd.read_csv(join(TABLES, 'Ad_table.csv'))\n"
     ]
    }
   ],
   "source": [
    "ad_data = pd.read_csv(join(TABLES, 'Ad_table.csv'))\n",
    "ad_data.rename(columns={' Genmodel': 'Genmodel', ' Genmodel_ID': 'Genmodel_ID'}, inplace=True)\n",
    "\n",
    "basic_data = pd.read_csv(join(TABLES, 'Basic_table.csv'))\n",
    "\n",
    "image_data = pd.read_csv(join(TABLES, 'Image_table.csv'))\n",
    "image_data.rename(columns={' Image_ID': 'Image_ID', ' Image_name': 'Image_name', ' Predicted_viewpoint':'Predicted_viewpoint', ' Quality_check':'Quality_check'}, inplace=True)\n",
    "\n",
    "price_data = pd.read_csv(join(TABLES, 'Price_table.csv'))\n",
    "price_data.rename(columns={' Genmodel': 'Genmodel', ' Genmodel_ID': 'Genmodel_ID', ' Year': 'Year', ' Entry_price': 'Entry_price'}, inplace=True)\n",
    "\n",
    "sales_data = pd.read_csv(join(TABLES, 'Sales_table.csv'))\n",
    "sales_data.rename(columns={'Genmodel ': 'Genmodel', 'Genmodel_ID ': 'Genmodel_ID'}, inplace=True)\n",
    "\n",
    "trim_data = pd.read_csv(join(TABLES, 'Trim_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "      <th>Quality_check</th>\n",
       "      <th>Adv_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$1$$1</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$1$$image_...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$10$$11</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$10$$image...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$4$$0</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$4$$image_...</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>2_1$$4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$8$$3</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$8$$image_...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$13$$8</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Grey$$2_1$$13$$image...</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>2_1$$13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451766</th>\n",
       "      <td>96_18</td>\n",
       "      <td>96_18$$919$$3</td>\n",
       "      <td>Volvo$$XC90$$2019$$White$$96_18$$919$$image_3.jpg</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96_18$$919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451771</th>\n",
       "      <td>97_1</td>\n",
       "      <td>97_1$$1$$1</td>\n",
       "      <td>Westfield$$Sport$$2006$$Yellow$$97_1$$1$$image...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97_1$$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451772</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$2$$14</td>\n",
       "      <td>Zenos$$E10$$2016$$Green$$99_1$$2$$image_14.jpg</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99_1$$2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451775</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$3$$1</td>\n",
       "      <td>Zenos$$E10$$2016$$Grey$$99_1$$3$$image_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>99_1$$3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451780</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$1$$0</td>\n",
       "      <td>Zenos$$E10$$2016$$Red$$99_1$$1$$image_0.jpg</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99_1$$1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247236 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genmodel_ID       Image_ID  \\\n",
       "0               2_1      2_1$$1$$1   \n",
       "1               2_1    2_1$$10$$11   \n",
       "8               2_1      2_1$$4$$0   \n",
       "14              2_1      2_1$$8$$3   \n",
       "18              2_1     2_1$$13$$8   \n",
       "...             ...            ...   \n",
       "1451766       96_18  96_18$$919$$3   \n",
       "1451771        97_1     97_1$$1$$1   \n",
       "1451772        99_1    99_1$$2$$14   \n",
       "1451775        99_1     99_1$$3$$1   \n",
       "1451780        99_1     99_1$$1$$0   \n",
       "\n",
       "                                                Image_name  \\\n",
       "0        Abarth$$124 Spider$$2017$$Blue$$2_1$$1$$image_...   \n",
       "1        Abarth$$124 Spider$$2017$$Blue$$2_1$$10$$image...   \n",
       "8        Abarth$$124 Spider$$2017$$Blue$$2_1$$4$$image_...   \n",
       "14       Abarth$$124 Spider$$2017$$Blue$$2_1$$8$$image_...   \n",
       "18       Abarth$$124 Spider$$2017$$Grey$$2_1$$13$$image...   \n",
       "...                                                    ...   \n",
       "1451766  Volvo$$XC90$$2019$$White$$96_18$$919$$image_3.jpg   \n",
       "1451771  Westfield$$Sport$$2006$$Yellow$$97_1$$1$$image...   \n",
       "1451772     Zenos$$E10$$2016$$Green$$99_1$$2$$image_14.jpg   \n",
       "1451775       Zenos$$E10$$2016$$Grey$$99_1$$3$$image_1.jpg   \n",
       "1451780        Zenos$$E10$$2016$$Red$$99_1$$1$$image_0.jpg   \n",
       "\n",
       "         Predicted_viewpoint Quality_check      Adv_ID  \n",
       "0                         45           NaN      2_1$$1  \n",
       "1                         45           NaN     2_1$$10  \n",
       "8                          0             P      2_1$$4  \n",
       "14                         0           NaN      2_1$$8  \n",
       "18                         0             P     2_1$$13  \n",
       "...                      ...           ...         ...  \n",
       "1451766                  225           NaN  96_18$$919  \n",
       "1451771                   45           NaN     97_1$$1  \n",
       "1451772                  180           NaN     99_1$$2  \n",
       "1451775                    0             P     99_1$$3  \n",
       "1451780                  225           NaN     99_1$$1  \n",
       "\n",
       "[247236 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parser_adv_id(x):\n",
    "  split = x[\"Image_ID\"].split('$$')\n",
    "  return f\"{split[0]}$${split[1]}\"\n",
    "\n",
    "image_data[\"Adv_ID\"] = image_data.apply(lambda x: parser_adv_id(x), axis=1)\n",
    "if front_view_only:\n",
    "  image_data = image_data[(image_data[\"Quality_check\"]==\"P\")&(image_data[\"Predicted_viewpoint\"]==0)]\n",
    "image_data.drop_duplicates(subset=['Adv_ID'], inplace=True)\n",
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268255\n",
      "224724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Engin_size</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>60000</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$13</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>53444</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$15</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Black</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>61500</td>\n",
       "      <td>6.7L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>16500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$16</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>49700</td>\n",
       "      <td>4.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>29500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>75000</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224719</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>100390</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224720</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>149000</td>\n",
       "      <td>2.0L</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224721</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>98167</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224722</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>152230</td>\n",
       "      <td>1.8L</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1495</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224723</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>111000</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224724 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Maker Genmodel Genmodel_ID     Adv_ID  Adv_year  Adv_month   Color  \\\n",
       "0       Bentley   Arnage        10_1    10_1$$1      2018          4  Silver   \n",
       "1       Bentley   Arnage        10_1   10_1$$13      2018          4  Silver   \n",
       "2       Bentley   Arnage        10_1   10_1$$15      2018          4   Black   \n",
       "3       Bentley   Arnage        10_1   10_1$$16      2017         12    Blue   \n",
       "4       Bentley   Arnage        10_1   10_1$$18      2018          4   White   \n",
       "...         ...      ...         ...        ...       ...        ...     ...   \n",
       "224719    Volvo      V50        96_9  96_9$$353      2018          5  Silver   \n",
       "224720    Volvo      V50        96_9  96_9$$374      2018          5  Silver   \n",
       "224721    Volvo      V50        96_9  96_9$$457      2018          5    Grey   \n",
       "224722    Volvo      V50        96_9  96_9$$477      2018          2    Grey   \n",
       "224723    Volvo      V50        96_9  96_9$$525      2018          5  Silver   \n",
       "\n",
       "        Reg_year Bodytype Runned_Miles Engin_size    Gearbox Fuel_type  Price  \\\n",
       "0         2000.0   Saloon        60000       6.8L  Automatic    Petrol  21500   \n",
       "1         2000.0   Saloon        53444       6.8L  Automatic    Petrol  21995   \n",
       "2         2000.0   Saloon        61500       6.7L  Automatic    Petrol  16500   \n",
       "3         2000.0   Saloon        49700       4.4L  Automatic    Petrol  29500   \n",
       "4         2000.0   Saloon        75000       6.8L  Automatic    Petrol  17995   \n",
       "...          ...      ...          ...        ...        ...       ...    ...   \n",
       "224719    2004.0   Estate       100390       2.4L  Automatic    Petrol   1999   \n",
       "224720    2004.0   Estate       149000       2.0L     Manual    Diesel   1450   \n",
       "224721    2004.0   Estate        98167       2.4L  Automatic    Petrol   3995   \n",
       "224722    2004.0   Estate       152230       1.8L     Manual    Petrol   1495   \n",
       "224723    2004.0   Estate       111000       2.4L  Automatic    Petrol   2895   \n",
       "\n",
       "        Seat_num  Door_num  Entry_price  Year  \n",
       "0            5.0       4.0       145000  2000  \n",
       "1            5.0       4.0       145000  2000  \n",
       "2            NaN       NaN       145000  2000  \n",
       "3            5.0       4.0       145000  2000  \n",
       "4            5.0       4.0       145000  2000  \n",
       "...          ...       ...          ...   ...  \n",
       "224719       5.0       5.0        17165  2004  \n",
       "224720       5.0       5.0        17165  2004  \n",
       "224721       5.0       5.0        17165  2004  \n",
       "224722       5.0       5.0        17165  2004  \n",
       "224723       5.0       5.0        17165  2004  \n",
       "\n",
       "[224724 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ad_data))\n",
    "feature_df = ad_data.merge(price_data[['Genmodel_ID', 'Entry_price', 'Year']], left_on=['Genmodel_ID','Reg_year'], right_on=['Genmodel_ID','Year'])\n",
    "print(len(feature_df))\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = feature_df.merge(image_data[['Adv_ID', 'Image_name', 'Predicted_viewpoint']], left_on=['Adv_ID'], right_on=['Adv_ID'])\n",
    "assert data_df[\"Adv_ID\"].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "      <th>Engine_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>60000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$1$$image_...</td>\n",
       "      <td>45</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$13</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>53444</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$13$$image...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$16</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>49700</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>29500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Blue$$10_1$$16$$image_1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>75000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$White$$10_1$$18$$image_...</td>\n",
       "      <td>90</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$26</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>98000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17945</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$26$$image...</td>\n",
       "      <td>225</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209030</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>100390</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209031</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>149000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209032</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>98167</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209033</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>152230</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1495</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg</td>\n",
       "      <td>315</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209034</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>111000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg</td>\n",
       "      <td>135</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184562 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Maker Genmodel Genmodel_ID     Adv_ID  Adv_year  Adv_month   Color  \\\n",
       "0       Bentley   Arnage        10_1    10_1$$1      2018          4  Silver   \n",
       "1       Bentley   Arnage        10_1   10_1$$13      2018          4  Silver   \n",
       "3       Bentley   Arnage        10_1   10_1$$16      2017         12    Blue   \n",
       "4       Bentley   Arnage        10_1   10_1$$18      2018          4   White   \n",
       "5       Bentley   Arnage        10_1   10_1$$26      2017          5  Silver   \n",
       "...         ...      ...         ...        ...       ...        ...     ...   \n",
       "209030    Volvo      V50        96_9  96_9$$353      2018          5  Silver   \n",
       "209031    Volvo      V50        96_9  96_9$$374      2018          5  Silver   \n",
       "209032    Volvo      V50        96_9  96_9$$457      2018          5    Grey   \n",
       "209033    Volvo      V50        96_9  96_9$$477      2018          2    Grey   \n",
       "209034    Volvo      V50        96_9  96_9$$525      2018          5  Silver   \n",
       "\n",
       "        Reg_year Bodytype Runned_Miles    Gearbox Fuel_type  Price  Seat_num  \\\n",
       "0         2000.0   Saloon        60000  Automatic    Petrol  21500       5.0   \n",
       "1         2000.0   Saloon        53444  Automatic    Petrol  21995       5.0   \n",
       "3         2000.0   Saloon        49700  Automatic    Petrol  29500       5.0   \n",
       "4         2000.0   Saloon        75000  Automatic    Petrol  17995       5.0   \n",
       "5         2000.0   Saloon        98000  Automatic    Petrol  17945       5.0   \n",
       "...          ...      ...          ...        ...       ...    ...       ...   \n",
       "209030    2004.0   Estate       100390  Automatic    Petrol   1999       5.0   \n",
       "209031    2004.0   Estate       149000     Manual    Diesel   1450       5.0   \n",
       "209032    2004.0   Estate        98167  Automatic    Petrol   3995       5.0   \n",
       "209033    2004.0   Estate       152230     Manual    Petrol   1495       5.0   \n",
       "209034    2004.0   Estate       111000  Automatic    Petrol   2895       5.0   \n",
       "\n",
       "        Door_num  Entry_price  Year  \\\n",
       "0            4.0       145000  2000   \n",
       "1            4.0       145000  2000   \n",
       "3            4.0       145000  2000   \n",
       "4            4.0       145000  2000   \n",
       "5            4.0       145000  2000   \n",
       "...          ...          ...   ...   \n",
       "209030       5.0        17165  2004   \n",
       "209031       5.0        17165  2004   \n",
       "209032       5.0        17165  2004   \n",
       "209033       5.0        17165  2004   \n",
       "209034       5.0        17165  2004   \n",
       "\n",
       "                                               Image_name  \\\n",
       "0       Bentley$$Arnage$$2000$$Silver$$10_1$$1$$image_...   \n",
       "1       Bentley$$Arnage$$2000$$Silver$$10_1$$13$$image...   \n",
       "3       Bentley$$Arnage$$2000$$Blue$$10_1$$16$$image_1...   \n",
       "4       Bentley$$Arnage$$2000$$White$$10_1$$18$$image_...   \n",
       "5       Bentley$$Arnage$$2000$$Silver$$10_1$$26$$image...   \n",
       "...                                                   ...   \n",
       "209030   Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg   \n",
       "209031   Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg   \n",
       "209032     Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg   \n",
       "209033     Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg   \n",
       "209034   Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg   \n",
       "\n",
       "        Predicted_viewpoint  Engine_size  \n",
       "0                        45          6.8  \n",
       "1                         0          6.8  \n",
       "3                         0          4.4  \n",
       "4                        90          6.8  \n",
       "5                       225          6.8  \n",
       "...                     ...          ...  \n",
       "209030                   45          2.4  \n",
       "209031                    0          2.0  \n",
       "209032                   45          2.4  \n",
       "209033                  315          1.8  \n",
       "209034                  135          2.4  \n",
       "\n",
       "[184562 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_engine_size(x):\n",
    "  return float(x['Engin_size'][:-1])\n",
    "\n",
    "data_df.dropna(inplace=True)\n",
    "data_df['Engine_size'] = data_df.apply(lambda x: extract_engine_size(x), axis=1)\n",
    "data_df.drop(columns=['Engin_size'], inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maker                   object\n",
       "Genmodel                object\n",
       "Genmodel_ID             object\n",
       "Adv_ID                  object\n",
       "Adv_year                 int64\n",
       "Adv_month                int64\n",
       "Color                   object\n",
       "Reg_year               float64\n",
       "Bodytype                object\n",
       "Runned_Miles            object\n",
       "Gearbox                 object\n",
       "Fuel_type               object\n",
       "Price                   object\n",
       "Seat_num               float64\n",
       "Door_num               float64\n",
       "Entry_price              int64\n",
       "Year                     int64\n",
       "Image_name              object\n",
       "Predicted_viewpoint      int64\n",
       "Engine_size            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = data_df.loc[:,'Adv_ID']\n",
    "image_name_df = data_df.loc[:,'Image_name']\n",
    "viewpoint_df = data_df.loc[:,'Predicted_viewpoint']\n",
    "\n",
    "continuous_df = data_df.loc[:,(\n",
    "  'Adv_year',\n",
    "  'Adv_month',\n",
    "  'Reg_year',\n",
    "  'Runned_Miles',\n",
    "  'Price',\n",
    "  'Seat_num',\n",
    "  'Door_num',\n",
    "  'Entry_price', \n",
    "  'Engine_size'\n",
    "  )]\n",
    "\n",
    "categorical_ids = ['Color',\n",
    "  'Bodytype',\n",
    "  'Gearbox',\n",
    "  'Fuel_type',\n",
    "  'Genmodel_ID']\n",
    "\n",
    "\n",
    "\n",
    "categorical_df = data_df.loc[:,categorical_ids]\n",
    "\n",
    "continuous_df['Runned_Miles'] = pd.to_numeric(continuous_df['Runned_Miles'], errors='coerce')\n",
    "continuous_df['Price'] = pd.to_numeric(continuous_df['Price'], errors='coerce')\n",
    "\n",
    "# normalize\n",
    "continuous_df=(continuous_df-continuous_df.mean())/continuous_df.std()\n",
    "\n",
    "categorical_df['Color'] = categorical_df['Color'].astype('category')\n",
    "categorical_df['Bodytype'] = categorical_df['Bodytype'].astype('category')\n",
    "categorical_df['Gearbox'] = categorical_df['Gearbox'].astype('category')\n",
    "categorical_df['Fuel_type'] = categorical_df['Fuel_type'].astype('category')\n",
    "categorical_df['Genmodel_ID'] = categorical_df['Genmodel_ID'].astype('category')\n",
    "\n",
    "cat_columns = categorical_df.select_dtypes(['category']).columns\n",
    "\n",
    "categorical_df[cat_columns] = categorical_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data_df = pd.concat([id_df, continuous_df, categorical_df, image_name_df, viewpoint_df], axis=1)\n",
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_population = 100\n",
    "values = (data_df.value_counts(subset=['Genmodel_ID'])>=minimum_population).values\n",
    "codes = (data_df.value_counts(subset=['Genmodel_ID'])>=minimum_population).index\n",
    "populated_codes = []\n",
    "for i, v in enumerate(values):\n",
    "  if v:\n",
    "    populated_codes.append(int(codes[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(populated_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Engine_size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_3$$1</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-1.311853</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.906021</td>\n",
       "      <td>6.323766</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Grey$$10_3$$1$$image_...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10_3$$3</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.830929</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.848026</td>\n",
       "      <td>6.594044</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Silver$$10_3$$3$$imag...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10_3$$10</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.815638</td>\n",
       "      <td>6.210746</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Blue$$10_3$$10$$image...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10_3$$11</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.823261</td>\n",
       "      <td>6.108246</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$White$$10_3$$11$$imag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10_3$$12</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-1.061788</td>\n",
       "      <td>7.133519</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Grey$$10_3$$12$$image...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209030</th>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.145516</td>\n",
       "      <td>-0.581038</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209031</th>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>2.282258</td>\n",
       "      <td>-0.610655</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.147646</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209032</th>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.093532</td>\n",
       "      <td>-0.473358</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209033</th>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-1.792777</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>2.357791</td>\n",
       "      <td>-0.608227</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>-0.111537</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209034</th>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.393631</td>\n",
       "      <td>-0.532701</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176414 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Adv_ID  Adv_year  Adv_month  Reg_year  Runned_Miles     Price  \\\n",
       "28        10_3$$1  0.012811  -1.311853  0.876887     -0.906021  6.323766   \n",
       "29        10_3$$3  0.012811  -0.830929  0.876887     -0.848026  6.594044   \n",
       "31       10_3$$10  0.012811   0.130919  0.876887     -0.815638  6.210746   \n",
       "32       10_3$$11  0.012811   0.611842  0.876887     -0.823261  6.108246   \n",
       "33       10_3$$12  0.012811   0.130919  0.876887     -1.061788  7.133519   \n",
       "...           ...       ...        ...       ...           ...       ...   \n",
       "209030  96_9$$353  0.012811  -0.350005 -1.900760      1.145516 -0.581038   \n",
       "209031  96_9$$374  0.012811  -0.350005 -1.900760      2.282258 -0.610655   \n",
       "209032  96_9$$457  0.012811  -0.350005 -1.900760      1.093532 -0.473358   \n",
       "209033  96_9$$477  0.012811  -1.792777 -1.900760      2.357791 -0.608227   \n",
       "209034  96_9$$525  0.012811  -0.350005 -1.900760      1.393631 -0.532701   \n",
       "\n",
       "        Seat_num  Door_num  Entry_price  Engine_size  Color  Bodytype  \\\n",
       "28      0.135216   0.61833     6.285820     5.331307      8        10   \n",
       "29      0.135216   0.61833     6.285820     5.331307     18        10   \n",
       "31      0.135216   0.61833     6.285820     5.331307      2        10   \n",
       "32      0.135216   0.61833     6.285820     5.331307     20        10   \n",
       "33      0.135216   0.61833     6.285820     5.331307      8        10   \n",
       "...          ...       ...          ...          ...    ...       ...   \n",
       "209030  0.135216   0.61833    -0.204064     0.666012     18         4   \n",
       "209031  0.135216   0.61833    -0.204064     0.147646     18         4   \n",
       "209032  0.135216   0.61833    -0.204064     0.666012      8         4   \n",
       "209033  0.135216   0.61833    -0.204064    -0.111537      8         4   \n",
       "209034  0.135216   0.61833    -0.204064     0.666012     18         4   \n",
       "\n",
       "        Gearbox  Fuel_type  Genmodel_ID  \\\n",
       "28            0          8            0   \n",
       "29            0          8            0   \n",
       "31            0          8            0   \n",
       "32            0          8            0   \n",
       "33            0          8            0   \n",
       "...         ...        ...          ...   \n",
       "209030        0          8          285   \n",
       "209031        1          1          285   \n",
       "209032        0          8          285   \n",
       "209033        1          8          285   \n",
       "209034        0          8          285   \n",
       "\n",
       "                                               Image_name  Predicted_viewpoint  \n",
       "28      Bentley$$Bentayga$$2016$$Grey$$10_3$$1$$image_...                  225  \n",
       "29      Bentley$$Bentayga$$2016$$Silver$$10_3$$3$$imag...                  225  \n",
       "31      Bentley$$Bentayga$$2016$$Blue$$10_3$$10$$image...                  225  \n",
       "32      Bentley$$Bentayga$$2016$$White$$10_3$$11$$imag...                    0  \n",
       "33      Bentley$$Bentayga$$2016$$Grey$$10_3$$12$$image...                    0  \n",
       "...                                                   ...                  ...  \n",
       "209030   Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg                   45  \n",
       "209031   Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg                    0  \n",
       "209032     Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg                   45  \n",
       "209033     Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg                  315  \n",
       "209034   Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg                  135  \n",
       "\n",
       "[176414 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df[data_df['Genmodel_ID'].isin(populated_codes)]\n",
    "map = {}\n",
    "for i,l in enumerate(data_df['Genmodel_ID'].unique()):\n",
    "  map[l] = i\n",
    "data_df['Genmodel_ID'] = data_df['Genmodel_ID'].map(map)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176414/176414 [11:24<00:00, 257.67it/s] \n"
     ]
    }
   ],
   "source": [
    "bad_indices = []\n",
    "for indx, row in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "    im_name = row['Image_name']\n",
    "    split = im_name.split('$$')\n",
    "    path = join(BASE, 'resized_DVM', split[0], split[1], split[2], split[3], im_name)\n",
    "    if not os.path.exists(path):\n",
    "        bad_indices.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(bad_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ids = list(data_df['Adv_ID'])\n",
    "addendum = '_all_views'\n",
    "non_feature_columns = ['Adv_ID', 'Image_name', 'Predicted_viewpoint', 'Genmodel_ID']\n",
    "if front_view_only:\n",
    "  train_set_ids, test_ids = train_test_split(_ids, test_size=0.1, random_state=2022)\n",
    "  train_ids, val_ids = train_test_split(train_set_ids, test_size=0.2, random_state=2022)\n",
    "  \n",
    "  bad_indices_train = torch.load(join(FEATURES, f'bad_indices_train{addendum}.pt'))\n",
    "  bad_indices_val = torch.load(join(FEATURES, f'bad_indices_val{addendum}.pt'))\n",
    "\n",
    "  print(f'Val length before {len(val_ids)}')\n",
    "  for _id in bad_indices_val:\n",
    "      val_ids.remove(_id)\n",
    "  print(f'Val length after {len(val_ids)}')\n",
    "\n",
    "  print(f'Train length before {len(train_ids)}')\n",
    "  for _id in bad_indices_train:\n",
    "      train_ids.remove(_id)\n",
    "  print(f'Train length after {len(train_ids)}')\n",
    "else:\n",
    "  addendum = '_all_views'\n",
    "  train_set_ids, test_ids = train_test_split(_ids, test_size=0.5, random_state=2022, stratify=data_df['Genmodel_ID'])\n",
    "  train_ids, val_ids = train_test_split(train_set_ids, test_size=0.2, random_state=2022, stratify=data_df[data_df['Adv_ID'].isin(train_set_ids)]['Genmodel_ID'])\n",
    "\n",
    "check_or_save(train_ids, join(FEATURES, f'train_ids{addendum}.pt'))\n",
    "check_or_save(val_ids, join(FEATURES, f'val_ids{addendum}.pt'))\n",
    "check_or_save(test_ids, join(FEATURES, f'test_ids{addendum}.pt'))\n",
    "\n",
    "train_df = data_df.set_index('Adv_ID').loc[train_ids]\n",
    "val_df = data_df.set_index('Adv_ID').loc[val_ids]\n",
    "test_df = data_df.set_index('Adv_ID').loc[test_ids]\n",
    "\n",
    "train_labels_all = list(train_df['Genmodel_ID'])\n",
    "val_labels_all = list(val_df['Genmodel_ID'])\n",
    "test_labels_all = list(test_df['Genmodel_ID'])\n",
    "\n",
    "check_or_save(train_labels_all, join(FEATURES,f'labels_model_all_train{addendum}.pt'))\n",
    "check_or_save(val_labels_all, join(FEATURES,f'labels_model_all_val{addendum}.pt'))\n",
    "check_or_save(test_labels_all, join(FEATURES,f'labels_model_all_test{addendum}.pt'))\n",
    "\n",
    "check_or_save(train_df.loc[:,~train_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_train_noOH{addendum}.csv'), index=False, header=False)\n",
    "check_or_save(val_df.loc[:,~val_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_val_noOH{addendum}.csv'), index=False, header=False)\n",
    "check_or_save(test_df.loc[:,~test_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_test_noOH{addendum}.csv'), index=False, header=False)\n",
    "\n",
    "check_or_save(train_df, join(FEATURES,f'dvm_full_features_train_noOH{addendum}.csv'), index=True, header=True)\n",
    "check_or_save(val_df, join(FEATURES,f'dvm_full_features_val_noOH{addendum}.csv'), index=True, header=True)\n",
    "check_or_save(test_df, join(FEATURES,f'dvm_full_features_test_noOH{addendum}.csv'), index=True, header=True)\n",
    "\n",
    "lengths = [1 for i in range(len(continuous_df.columns))]\n",
    "\n",
    "if 'Genmodel_ID' in categorical_ids:\n",
    "  categorical_ids.remove('Genmodel_ID')\n",
    "max = list(data_df[categorical_ids].max(axis=0))\n",
    "max = [i+1 for i in max]\n",
    "lengths = lengths + max\n",
    "check_or_save(lengths, join(FEATURES, f'tabular_lengths{addendum}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(df):\n",
    "  paths = []\n",
    "  for indx, row in df.iterrows():\n",
    "      im_name = row['Image_name']\n",
    "      split = im_name.split('$$')\n",
    "      path = join(BASE, 'resized_DVM', split[0], split[1], split[2], split[3], im_name)\n",
    "      paths.append(path)\n",
    "  return paths\n",
    "\n",
    "# For big dataset need to save only paths to load live\n",
    "addendum = '_all_views'\n",
    "train_df = pd.read_csv(join(FEATURES,f'dvm_full_features_train_noOH{addendum}.csv'))\n",
    "val_df = pd.read_csv(join(FEATURES,f'dvm_full_features_val_noOH{addendum}.csv'))\n",
    "test_df = pd.read_csv(join(FEATURES,f'dvm_full_features_test_noOH{addendum}.csv'))\n",
    "\n",
    "for df, name in zip([train_df, val_df, test_df], ['train', 'val', 'test']):\n",
    "  paths = get_paths(df)\n",
    "  check_or_save(paths, join(FEATURES, f'{name}_paths{addendum}.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Normalized Ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df, t_split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([train_df, val_df, test_df], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      7\u001b[0m   images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i,row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      9\u001b[0m     image_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     split \u001b[38;5;241m=\u001b[39m image_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if front_view_only:\n",
    "  IMAGES = join(BASE, 'Confirmed_fronts')\n",
    "else:\n",
    "  IMAGES = join(BASE, 'resized_DVM')\n",
    "\n",
    "for df, t_split in zip([train_df, val_df, test_df], ['train', 'val', 'test']):\n",
    "  images = []\n",
    "  for i,row in df.iterrows():\n",
    "    image_name = row['Image_name']\n",
    "    split = image_name.split('$$')\n",
    "    \n",
    "    if front_view_only:\n",
    "      path = join(IMAGES,split[0],split[2],image_name)\n",
    "    else:\n",
    "      path = join(IMAGES,split[0],split[1],split[2],split[3],image_name)\n",
    "    images.append(read_image(path))\n",
    "  images_t = torch.stack(images).float()\n",
    "  images_t = images_t/255\n",
    "  check_or_save(images_t, join(FEATURES, f'{t_split}_images{addendum}.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Low Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_data_split(df, nclasses):\n",
    "  critical_ids = df.groupby('Genmodel_ID', as_index=False).head(n=1)['Adv_ID']\n",
    "  other_ids = df.loc[~df['Adv_ID'].isin(critical_ids)]['Adv_ID'].values\n",
    "  to_fill_size = (int(len(df)*0.1)-len(critical_ids))\n",
    "  stratify = None\n",
    "  if to_fill_size >= nclasses:\n",
    "    stratify = df.set_index('Adv_ID').loc[other_ids]['Genmodel_ID']\n",
    "  if to_fill_size > 0:\n",
    "    _, low_data_ids = train_test_split(other_ids, test_size=to_fill_size, random_state=2023, stratify=stratify)\n",
    "  else:\n",
    "    low_data_ids = []\n",
    "  new_ids = np.concatenate([critical_ids,low_data_ids])\n",
    "  return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/train_images_all_views.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(join(FEATURES,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvm_full_features_train_noOH\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddendum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprev_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(join(FEATURES, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_ids\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddendum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprev_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m ims \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43maddendum\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlocation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprev_k\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(join(FEATURES, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_model_all_train\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddendum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprev_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m low_data_ids \u001b[38;5;241m=\u001b[39m low_data_split(df, nclasses)\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/train_images_all_views.pt'"
     ]
    }
   ],
   "source": [
    "addendum = '_all_views'\n",
    "data_str = 'images'\n",
    "location = \"\"\n",
    "non_feature_columns = ['Image_name', 'Genmodel_ID', 'Predicted_viewpoint', 'Adv_ID']\n",
    "nclasses = 151\n",
    "if addendum=='_all_views':\n",
    "  #data_str = 'paths'\n",
    "  #location = '_server'\n",
    "  nclasses = 286\n",
    "\n",
    "\n",
    "for k, prev_k in zip([0.1,0.01],['','_0.1']):\n",
    "  df = pd.read_csv(join(FEATURES,f'dvm_full_features_train_noOH{addendum}{prev_k}.csv'))\n",
    "  ids = torch.load(join(FEATURES, f'train_ids{addendum}{prev_k}.pt'))\n",
    "  ims = torch.load(join(FEATURES, f'train_{data_str}{addendum}{location}{prev_k}.pt'))\n",
    "  labels = torch.load(join(FEATURES, f'labels_model_all_train{addendum}{prev_k}.pt'))\n",
    "  low_data_ids = low_data_split(df, nclasses)\n",
    "  true_false_mask = [i in low_data_ids for i in ids]\n",
    "  ld = [id for id in ids if id in low_data_ids]\n",
    "  low_data_ids = ld\n",
    "  low_data_df = df.loc[true_false_mask]\n",
    "  if addendum=='_all_views' and not data_str=='images':\n",
    "    ims = np.array(ims)\n",
    "  else:  \n",
    "    ims = torch.tensor(ims)\n",
    "  low_data_ims = ims[true_false_mask]\n",
    "  low_data_labels = [labels[i] for i in range(len(ids)) if ids[i] in low_data_ids]\n",
    "\n",
    "  \n",
    "  check_or_save(low_data_df.loc[:,~low_data_df.columns.isin(non_feature_columns)], join(FEATURES,f'dvm_features_train_noOH{addendum}_{k}.csv'), index=False, header=False)\n",
    "  check_or_save(low_data_df, join(FEATURES,f'dvm_full_features_train_noOH{addendum}_{k}.csv'), index=False, header=True)\n",
    "  check_or_save(low_data_ims, join(FEATURES, f'train_{data_str}{addendum}{location}_{k}.pt'))\n",
    "  check_or_save(low_data_ids, join(FEATURES, f'train_ids{addendum}_{k}.pt'))\n",
    "  check_or_save(low_data_labels, join(FEATURES, f'labels_model_all_train{addendum}_{k}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "for k in [0.1, 0.01]:\n",
    "  low_data_ids = torch.load(join(FEATURES, f'{split}_ids{addendum}_{k}.pt'))\n",
    "  low_data_df = pd.read_csv(join(FEATURES,f'dvm_full_features_{split}_noOH{addendum}_{k}.csv'))\n",
    "  print(low_data_df.value_counts('Genmodel_ID'))\n",
    "  print(len(low_data_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/val_images.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m TABLES \u001b[38;5;241m=\u001b[39m join(BASE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtables_V2.0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m FEATURES \u001b[38;5;241m=\u001b[39m join(BASE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_images.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/val_images.pt'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "from os.path import join\n",
    "\n",
    "BASE = '/home/stympopper/data/DVMdata'\n",
    "TABLES = join(BASE, 'tables_V2.0')\n",
    "FEATURES = join(BASE, 'features')\n",
    "\n",
    "train_images = torch.load(join(FEATURES, f'val_images.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.RandomApply([transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8)], p=0.8),\n",
    "      transforms.RandomGrayscale(p=0.2),\n",
    "      transforms.RandomApply([transforms.GaussianBlur(kernel_size=29, sigma=(0.1, 2.0))],p=0.5),\n",
    "      transforms.RandomResizedCrop(size=(img_size,img_size), scale=(0.2, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "      transforms.RandomHorizontalFlip(p=0.5),\n",
    "      transforms.Resize(size=(img_size,img_size)),\n",
    "      transforms.Lambda(lambda x : x.float())\n",
    "    ])\n",
    "\n",
    "im = train_images[1]\n",
    "im_t = transform(im)\n",
    "_ = plt.imshow(im_t.permute(1,2,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Physical Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding missing values to physical table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill using other values\n",
    "physical_df_orig = pd.read_csv(join(TABLES,'Ad_table (extra).csv'))\n",
    "physical_df_orig.rename(columns={' Genmodel_ID':'Genmodel_ID', ' Genmodel':'Genmodel'}, inplace=True)\n",
    "\n",
    "# Manual touches\n",
    "\n",
    "# Peugeot RCZ\n",
    "physical_df_orig.loc[physical_df_orig['Genmodel_ID'] == '69_36','Wheelbase']=2612\n",
    "# Ford Grand C-Max\n",
    "physical_df_orig.loc[physical_df_orig['Genmodel_ID'] == '29_20','Wheelbase']=2788 \n",
    "\n",
    "def fill_from_other_entry(row):\n",
    "    for attr in ['Wheelbase', 'Length', 'Width', 'Height']:\n",
    "        if pd.isna(row[attr]) or row[attr]==0:\n",
    "            other_rows = physical_df_orig.loc[physical_df_orig['Genmodel_ID']==row['Genmodel_ID']]\n",
    "            other_rows.dropna(subset=[attr], inplace=True)\n",
    "            other_rows.drop_duplicates(subset=[attr], inplace=True)\n",
    "            other_rows = other_rows[other_rows[attr]>0]\n",
    "            if len(other_rows)>0:\n",
    "                row[attr] = other_rows[attr].values[0]\n",
    "        print(f\"{attr} done\")\n",
    "    return row\n",
    "\n",
    "physical_df_orig = physical_df_orig.apply(fill_from_other_entry, axis=1)\n",
    "\n",
    "physical_df_orig.to_csv(join(FEATURES,'Ad_table_physical_filled.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add physical attributes to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/Ad_table_physical_filled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m-\u001b[39mjitter, jitter)\n\u001b[1;32m      5\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m2022\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m physical_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAd_table_physical_filled.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelbase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      8\u001b[0m     physical_df[attr] \u001b[38;5;241m=\u001b[39m physical_df[attr]\u001b[38;5;241m.\u001b[39mapply(add_jitter)\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/selfsuper/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/stympopper/data/DVMdata/features/Ad_table_physical_filled.csv'"
     ]
    }
   ],
   "source": [
    "# Add jitter to physical dimensions so they aren't just labels\n",
    "def add_jitter(x, jitter=50):\n",
    "    return x + random.randint(-jitter, jitter)\n",
    "\n",
    "random.seed(2022)\n",
    "physical_df = pd.read_csv(join(FEATURES,'Ad_table_physical_filled.csv'))\n",
    "for attr in ['Wheelbase', 'Length', 'Width', 'Height']:\n",
    "    physical_df[attr] = physical_df[attr].apply(add_jitter)\n",
    "physical_df.to_csv(join(FEATURES,'Ad_table_physical_filled_jittered_50.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ford ranger (29_30) has wrong height. Missing 1 in front... 805.0 instead of 1805.0\n",
    "# Mercedes Benz (59_29) wrong wheelbase, 5246.0 instead of 3106\n",
    "# Kia Rio (43_9) wrong wheelbase, 4065.0 instead of 2580\n",
    "# FIXED\n",
    "\n",
    "\n",
    "physical_df = pd.read_csv(join(FEATURES,'Ad_table_physical_filled_jittered_50.csv'))[['Adv_ID', 'Wheelbase','Height','Width','Length']]\n",
    "for v in ['_all_views']:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        features_df = pd.read_csv(join(FEATURES,f'dvm_full_features_{split}_noOH{v}.csv'))\n",
    "        merged_df = features_df.merge(physical_df, on='Adv_ID')\n",
    "        physical_only_df = merged_df[['Wheelbase','Height','Width','Length','Bodytype']]\n",
    "\n",
    "        for attr in ['Wheelbase','Height','Width','Length']:\n",
    "            assert merged_df[attr].isna().sum()==0\n",
    "            assert (merged_df[attr]==0).sum()==0\n",
    "\n",
    "        # normalize physical attributes\n",
    "        for attr in ['Wheelbase','Height','Width','Length']:\n",
    "            merged_df[attr] = (merged_df[attr]-merged_df[attr].mean())/merged_df[attr].std()\n",
    "            physical_only_df[attr] = (physical_only_df[attr]-physical_only_df[attr].mean())/physical_only_df[attr].std()\n",
    "\n",
    "        # Drop unwanted cols\n",
    "        non_feature_columns = ['Adv_ID', 'Image_name', 'Genmodel_ID']\n",
    "        if v == '_all_views':\n",
    "            non_feature_columns.append('Predicted_viewpoint')\n",
    "        merged_df = merged_df.drop(non_feature_columns, axis=1)\n",
    "\n",
    "        merged_df_cols = merged_df.columns.tolist()\n",
    "        rearranged_cols = merged_df_cols[-4:]+merged_df_cols[:-4]\n",
    "        merged_df = merged_df[rearranged_cols]\n",
    "        check_or_save(merged_df, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50.csv'), index=False, header=False)\n",
    "        check_or_save(physical_only_df, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_only_jittered_50.csv'), index=False, header=False)\n",
    "    lengths = torch.load(join(FEATURES,f'tabular_lengths{v}.pt'))\n",
    "    new_lengths = [1,1,1,1]\n",
    "    lengths = new_lengths + lengths\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical.pt'))\n",
    "    lengths = [1,1,1,1,13]\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical_only.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Labels to Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['_all_views']:\n",
    "    for split in ['train', 'val']:\n",
    "        labels = torch.load(join(FEATURES,f'labels_model_all_{split}{v}.pt'))\n",
    "        features = pd.read_csv(join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50.csv'), header=None)\n",
    "        features['label'] = labels\n",
    "        check_or_save(features, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50_labeled.csv'), index=False, header=False)\n",
    "    lengths = torch.load(join(FEATURES,f'tabular_lengths{v}_physical.pt'))\n",
    "    lengths.append(max(labels)+1)\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical_labeled.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('selfsuper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a21be7fe9607dfe0c8ee311f8a5f36f314167f49973cd8e355a42459a56bba0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
