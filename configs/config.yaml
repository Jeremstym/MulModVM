defaults:
  - _self_
  - models: resnet50
  - dataset: dvm_all_server

# Command Center
pretrain: False
run_eval: True

seeds: 
  - 2022
  - 2023
  - 2024
  - 2025
  - 2026
lr_finder_lrs: 
  - 3.e-2
  - 1.e-2
  - 3.e-3
  - 1.e-3
  - 3.e-4
  - 1.e-4
multitarget:

wandb_entity: 
data_base: 
num_workers: 0
persistent_workers: False
use_cache: True
num_sanity_val_steps: 2

wandb_project: 
sql_address: 


# Multimodal
weight_decay: 1.e-4
scheduler: anneal
anneal_max_epochs: 200
warmup_epochs: 10
temperature: 0.1
projection_dim: 128
use_projection_head: True

loss: clip
view: augmented
lambda_0: 0.5
momentum: 0.99

train_similarity_matrix:
val_similarity_matrix: 
threshold: 0.9
similarity_divisor: 2

tabular_pretrain_checkpoint:
pretrained_tabular_strategy: frozen
imaging_pretrain_checkpoint:
pretrained_imaging_strategy: trainable

multiple_lr: False

batch_size: 64
lr_eval: 1.e-3
weight_decay_eval: 0
val_check_interval: 1.0
check_val_every_n_epoch: 1

# Classifier
classifier_num_layers: 2
lr_classifier: 3.e-4
weight_decay_classifier: 1.e-4
online_mlp: True

# Imaging
augmentation_rate: 0.95
crop_scale_lower: 0.08

# tabular
corruption_rate: 0.3
one_hot: False
eval_one_hot: False
use_transformer: False
use_xtab: False
xtab_path: /home/stympopper/MulModVM/foundation_models/xtab.ckpt

encoder_num_layers: 2
projector_num_layers: 1
init_strat: kaiming

# tabular_transformer
tabular_tokenizer:
  _target_: models.TabularTokenizer.TabularTokenizer
  d_token: 192
tabular_transformer:
  _target_: autogluon.multimodal.models.ft_transformer.FT_Transformer
  d_token: 192
  n_self_blocks: 3
  n_cross_blocks: 3
  attention_n_heads: 8
  attention_dropout: 0.2
  attention_initialization: kaiming
  attention_normalization: layer_norm
  ffn_d_hidden: ${tabular_transformer.d_token}
  ffn_dropout: 0.1
  ffn_activation: reglu
  ffn_normalization: layer_norm
  residual_dropout: 0.1
  prenormalization: True
  first_prenormalization: False
  last_layer_query_idx: null
  cross_attention: False
  n_tokens: null # Only used when compressing the input sequence (`kv_compression_ratio is not None`)
  kv_compression_ratio: null # Only used when compressing the input sequence (`kv_compression_ratio is not None`)
  kv_compression_sharing: null # Only used when compressing the input sequence (`kv_compression_ratio is not None`)
  head_activation: False # Only used when using a projection head (`projection=True`)
  head_normalization: null # Only used when using a projection head (`projection=True`)
  d_out: null # Only used when using a projection head (`projection=True`)

# Evaluator
generate_embeddings: False
keep_projector: False
eval_train_augment_rate: 0.8
eval_classifier: linear
finetune_strategy: frozen

vec2vec: False
checkpoint_vec2vec: 

checkpoint:
datatype:
eval_datatype:

# General
seed: 2022
max_epochs: 5
log_images: False
use_wandb: True
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0
enable_progress_bar: True
offline: False
evaluate: True
test: False
test_and_eval: False
combine_train_and_val: False
weighted_sampler: False
classifier_freq: 5
unit_test: False
profiler: False
output_dir: /home/stympopper/MulModVM
missing_values: [] #[2695,11563]

transform:
version:
input_size:
transform_train:
transform_val:
transform_test:
dataset_length:
resume_training:
wandb_id:
wandb_name: null

labels_train_short:
labels_val_short:
data_train_tabular_short:
data_val_tabular_short:
data_train_imaging_short:
data_val_imaging_short:
field_lengths_tabular_short:
data_train_eval_tabular_short:
labels_train_eval_tabular_short:
data_val_eval_tabular_short:
labels_val_eval_tabular_short:
data_test_eval_tabular_short:
labels_test_eval_tabular_short:
data_train_eval_imaging_short:
labels_train_eval_imaging_short:
data_val_eval_imaging_short:
labels_val_eval_imaging_short:
data_test_eval_imaging_short:
labels_test_eval_imaging_short:
train_similarity_matrix_short: